---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# fastR

<!-- badges: start -->

<!-- badges: end -->

## The goal of PACKAGENAME is ...

The primary objective of the provided package is to:

-   Simplify the preprocessing steps for in-situ temperature data time series selection.

-   Enable users to focus on data analysis.

-   Facilitate access to AppEEARS data within R, particularly referencing datasets derived from remote sensing applications.

    <!-- -->

## Installation

You can install the development version of PACKAGENAME like so:

``` r
# devtools::install_github("ElenaScholz/PACKAGENAME")
```

## Prerequisites

-   InSitu or other Time Series Data with the Informations to be analysed (Should look similar to the provided datasets)
-   An account to NASA's EARTHDATA portal ([Create a new Account](http://urs.earthdata.nasa.gov) ) to download reference data

## Workflow

1.  Data Analysis of field Temperature Data

    1.  Read in data and reorganize it into a list of data frames

    2.  Improve the column readability by renaming them

    3.  Enhance data structure by mutating the date/time column

    4.  Aggregate data frames by Year, Month, Day or Season

2.  Exploration of the Datasets

    1.  Create simple plots to gain an overview of the logger data.

    2.  Utilize the 'show_appeears_products' function to explore all available AppEEARS products.

3.  Retrive Reference Data

    1.  Authenticate with AppEEARS using 'appeears_login' to obtain a token

    2.  Submit tasks to download reference data and filter all products by the topics for your analysis

4.  Data Download and Processing

    1.  After the task submission is done you'll receive an Email and you can start the data download

5.  Integration and Visualization

    1.  Apply similar pre-processing steps (1.1 -1.4) to the downloaded reference datasets

    2.  Plot logger data and reference datasets together

## Example

This codesnippet shows the workflow for preparing the data for the analysis

```{r example}
library(fastR)


input_directory <- system.file("extdata/", package = "fastR")

### 1. Read in the Datasets with the function "read_data"
  # for the given example datasets, the ID can be added from the filename. 
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
                      csv_comment_character = "#",
                      add_ID_from_filename = TRUE,
                      index_id = c(0, 6)
) 

  # take a look at the structure of raw_data and one dataset
str(raw_data)

### 2. Rename the columns to make the Analysis easier

sample_data <- rename_columns(raw_data, 
                               rename_map = list(Number = "No", 
                                                 Logger_ID = "Logger.ID", 
                                                 Time = "Time", 
                                                 Temperature_C  = "X1.oC",
                                                 Battery_Voltage = "HK.Bat.V"))

### 3. Date Conversion 
  # for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column. 


sample_data <- mutate_dates(sample_data, time_column = "Time",
                            time_format = "%d.%m.%Y %H:%M:%S")

head(sample_data)

```

What is special about using `README.Rmd` instead of just `README.md`? You can include R chunks like so:

```{r cars}
summary(cars)
```

You'll still need to render `README.Rmd` regularly, to keep `README.md` up-to-date. `devtools::build_readme()` is handy for this.

You can also embed plots, for example:

```{r pressure, echo = FALSE}
plot(pressure)
```

In that case, don't forget to commit and push the resulting figure files, so they display on GitHub and CRAN.
