### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is an sf-object
class(coordinates_transformed)
coordinates_transformed$coordinates_df
appeears_coordinates <- coordinates_transformed$coordinates_df
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
### 5. submit a processing task for the reference data
# in this case reference data for landsurface temperature (LST) and        Snow Cover is chosen (NDSI)
start_date <- min(sample_data$Date)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, filter_topic = "LST", token = token, start_date = start_date, end_date = end_date)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
### 2. create a spatial dataset, that converts the original                   coordinatesystem into longitude and latitude
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is a list containing an sf-object and a dataframe      for the download
class(coordinates_transformed)
appeears_coordinates <- coordinates_transformed$coordinates_df
### 3. Login to AppEEARS and generate a token
token <- appeears_login()
### 4. get an overview over all appeears products and choose which reference data you want to download
products <- show_appeears_products()
### 5. submit a processing task for the reference data
# in this case reference data for landsurface temperature (LST) and        Snow Cover is chosen (NDSI)
start_date <- min(sample_data$Date)
end_date <- max(sample_data$Date)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date)
devtools::load_all()
devtools::check()
library(fastR)
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
### 2. create a spatial dataset, that converts the original                   coordinatesystem into longitude and latitude
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is a list containing an sf-object and a dataframe      for the download
class(coordinates_transformed)
appeears_coordinates <- coordinates_transformed$coordinates_df
### 3. Login to AppEEARS and generate a token
token <- appeears_login()
### 4. get an overview over all appeears products and choose which reference data you want to download
products <- show_appeears_products()
### 5. submit a processing task for the reference data
# in this case reference data for landsurface temperature (LST) and        Snow Cover is chosen (NDSI)
start_date <- min(sample_data$Date)
end_date <- max(sample_data$Date)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date)
View(appeears_coordinates)
class(appeears_coordinates)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date, coordinates_dataframe = appeears_coordinates)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
### 2. create a spatial dataset, that converts the original                   coordinatesystem into longitude and latitude
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is a list containing an sf-object and a dataframe      for the download
class(coordinates_transformed)
appeears_coordinates <- coordinates_transformed$coordinates_df
### 3. Login to AppEEARS and generate a token
token <- appeears_login()
### 4. get an overview over all appeears products and choose which reference data you want to download
products <- show_appeears_products()
### 5. submit a processing task for the reference data
# in this case reference data for landsurface temperature (LST) and        Snow Cover is chosen (NDSI)
# make sure the format of the dates is in m-d-Y
start_date <- "01-01-2010"
end_date <- "06-10-2023"
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date, coordinates_dataframe = appeears_coordinates)
ndsi_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "NDSI", token = token, start_date = start_date, end_date = end_date, coordinates_dataframe = appeears_coordinates)
### 6. download the reference data
getwd()
devtools::build_readme()
devtools::build_readme()
.Last.error
devtools::build_readme()
devtools::build_readme()
devtools::check()
library(fastR)
devtools::build_readme()
devtools::build_readme()
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is a list containing an sf-object and a dataframe      for the download
class(coordinates_transformed)
appeears_coordinates <- coordinates_transformed$coordinates_df
token <- appeears_login()
products <- show_appeears_products()
# make sure the format of the dates is in m-d-Y
start_date <- "01-01-2010"
end_date <- "06-10-2023"
#lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date, coordinates_dataframe = appeears_coordinates)
#ndsi_submission <- submit_processing_task(task_name = "example_ndsi", products_df = products, topic_filter = "NDSI", token = token, start_date = start_date, end_date = end_date, coordinates_dataframe = appeears_coordinates)
output_directory = "define/your/output/directory"
download_task_bundle(task_id = 	"0e7e3f9a-1a6d-4791-9ea5-772901550201", token = token, ouput_directory = system.file("extdata/Referencedata/", package = "fastR"))
library(fastR)
output_directory = "define/your/output/directory"
download_task_bundle(task_id = 	"0e7e3f9a-1a6d-4791-9ea5-772901550201", token = token, ouput_directory = system.file("extdata/Referencedata/", package = "fastR"))
output_directory = system.file("extdata/Referencedata/", package = "fastR")
download_task_bundle(task_id = 	"0e7e3f9a-1a6d-4791-9ea5-772901550201", token = token, ouput_directory = output_directory)
ouput_directory = system.file("extdata/Referencedata/", package = "fastR")
download_task_bundle(task_id = 	"0e7e3f9a-1a6d-4791-9ea5-772901550201", token = token, ouput_directory = ouput_directory)
ouput_directory = system.file("extdata/Referencedata/", package = "fastR")
download_task_bundle(task_id = 	"0e7e3f9a-1a6d-4791-9ea5-772901550201", token = token, output_directory = output_directory)
download_task_bundle(task_id = "1994d74b-62bf-4544-ae46-5d485fd4d3a3"
, token = token, output_directory = output_directory)
ouput_directory = "/home/ela/Documents/R-FinalExam/packagetest/"
download_task_bundle(task_id = 	"0e7e3f9a-1a6d-4791-9ea5-772901550201", token = token, output_directory = output_directory)
download_task_bundle(task_id = 	"0e7e3f9a-1a6d-4791-9ea5-772901550201", token = token, output_directory = "/home/ela/Documents/R-FinalExam/examples/AppEEARS_data/")
download_task_bundle(task_id = "1994d74b-62bf-4544-ae46-5d485fd4d3a3"
, token = token, output_directory = "/home/ela/Documents/R-FinalExam/examples/AppEEARS_data/")
devtools::build_readme()
devtools::build_readme()
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
daily_temperature <- aggregate_data(sample_data, aggregation_type = "daily", temperature_column = "Temperature_C")
monthly_temperature <- aggregate_data(sample_data, aggregation_type = "monthly", temperature_column = "Temperature_C")
daily_plots <- create_daily_plots(daily_temperature)
View(daily_temperature)
class(daily_temperature$Date)
daily_plots <- create_daily_plots(daily_temperature)
devtools::load_all()
devtools::check()
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
library(fastR)
daily_temperature <- aggregate_data(sample_data, aggregation_type = "daily", temperature_column = "Temperature_C")
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
daily_temperature <- aggregate_data(sample_data, aggregation_type = "daily", temperature_column = "Temperature_C")
monthly_temperature <- aggregate_data(sample_data, aggregation_type = "monthly", temperature_column = "Temperature_C")
# generate simple plots to see the developement of the temperature over time
daily_plot <- create_daily_plot(daily_temperature)
daily_plot
library(fastR)
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
daily_temperature <- aggregate_data(sample_data, aggregation_type = "daily", temperature_column = "Temperature_C")
monthly_temperature <- aggregate_data(sample_data, aggregation_type = "monthly", temperature_column = "Temperature_C")
# generate simple plots to see the developement of the temperature over time
daily_plot <- create_daily_plot(daily_temperature)
daily_plot
daily_plot
daily_temp_plot <- ggplot2::ggplot(daily_temperature, aes(x = Julian, y = mean_temperature)) +
ggplot2::geom_line(color = '#6bd2db', linewidth = 1) +
ggplot2::theme_bw() +
ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = 10),
axis.title.x = ggplot2::element_blank(),
axis.title.y = ggplot2::element_blank()) +
ggplot2::ggtitle("Development of temperature over time") +
ggplot2::facet_wrap(~Year) +
ggplot2::labs(subtitle = paste("Logger ID:", unique(daily_temperature$Logger_ID)))
daily_temp_plot <- ggplot2::ggplot(daily_temperature, ggplot2::aes(x = Julian, y = mean_temperature)) +
ggplot2::geom_line(color = '#6bd2db', linewidth = 1) +
ggplot2::theme_bw() +
ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = 10),
axis.title.x = ggplot2::element_blank(),
axis.title.y = ggplot2::element_blank()) +
ggplot2::ggtitle("Development of temperature over time") +
ggplot2::facet_wrap(~Year) +
ggplot2::labs(subtitle = paste("Logger ID:", unique(daily_temperature$Logger_ID)))
daily_temp_plot
monthly_temp_plot <- ggplot(data, aes(Year, mean_temperature, colour = Month)) +
geom_point(size = 0.5) +
geom_smooth() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
axis.title.x = element_blank(),
legend.position = "none") +
labs(x = "Year",
y = "Mean Temperature") +
facet_wrap(~Month) +
ggtitle("Development of temperature per Month")
monthly_temp_plot <- ggplot2::ggplot(data, ggplot2::aes(Year, mean_temperature, colour = Month)) +
ggplot2::geom_point(size = 0.5) +
ggplot2::geom_smooth() +
ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = 10),
axis.title.x = ggplot2::element_blank(),
legend.position = "none") +
ggplot2::labs(x = "Year",
y = "Mean Temperature") +
ggplot2::facet_wrap(~Month) +
ggplot2::ggtitle("Development of temperature per Month")
monthly_temp_plot <- ggplot2::ggplot(monthly_temperature, ggplot2::aes(Year, mean_temperature, colour = Month)) +
ggplot2::geom_point(size = 0.5) +
ggplot2::geom_smooth() +
ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = 10),
axis.title.x = ggplot2::element_blank(),
legend.position = "none") +
ggplot2::labs(x = "Year",
y = "Mean Temperature") +
ggplot2::facet_wrap(~Month) +
ggplot2::ggtitle("Development of temperature per Month")
monthly_temp_plot
# generate simple plots to see the developement of the temperature over time
daily_temp_plot <- ggplot2::ggplot(daily_temperature, ggplot2::aes(x = Julian, y = mean_temperature)) +
ggplot2::geom_line(color = '#6bd2db', linewidth = 1) +
ggplot2::theme_bw() +
ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = 10),
axis.title.x = ggplot2::element_blank(),
axis.title.y = ggplot2::element_blank()) +
ggplot2::ggtitle("Development of temperature over time") +
ggplot2::facet_wrap(~Year) +
ggplot2::labs(subtitle = paste("Logger ID:", unique(daily_temperature$Logger_ID)))
daily_temp_plot
monthly_temp_plot <- ggplot2::ggplot(monthly_temperature, ggplot2::aes(Year, mean_temperature, colour = Month)) +
ggplot2::geom_point(size = 0.5) +
ggplot2::geom_smooth() +
ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = 10),
axis.title.x = ggplot2::element_blank(),
legend.position = "none") +
ggplot2::labs(x = "Year",
y = "Mean Temperature") +
ggplot2::facet_wrap(~Month) +
ggplot2::ggtitle("Development of temperature per Month")
monthly_temp_plot
devtools::build_readme()
library(fastR)
usethis::use_data_raw()
usethis::use_data()
usethis::use_data(DATASET)
usethis::use_data(DATASET.R)
usethis::use_data("DATASET.R")
## code to prepare `DATASET` dataset goes here
library(fastR)
library(dplyr)
#### used functions
# function to filter quality
filter_quality <- function(data, quality_column, acceptable_qualities) {
data %>%
dplyr::filter({{ quality_column }} %in% acceptable_qualities)
}
create_subset <- function(data, columns) {
data %>%
dplyr::select({{ columns }})
}
####
reference_data <- read_data("/home/ela/Documents/R-Projects/loggeranalysis/inst/extdata/Referencedata/",add_ID_from_filename = FALSE )
library(fastR)
library(dplyr)
# function to filter quality
filter_quality <- function(data, quality_column, acceptable_qualities) {
data %>%
dplyr::filter({{ quality_column }} %in% acceptable_qualities)
}
create_subset <- function(data, columns) {
data %>%
dplyr::select({{ columns }})
}
reference_data <- read_data("/home/ela/Documents/R-Projects/loggeranalysis/inst/extdata/Referencedata/",add_ID_from_filename = FALSE )
reference_data <- read_data("data-raw/raw-data/Referencedata/",add_ID_from_filename = FALSE )
reference_data <- read_data("data-raw/raw-data/",add_ID_from_filename = FALSE )
lst <- reference_data$`example-lst-MOD11A1-061-results.csv`
ndsi <- reference_data$`example-ndsi-MOD10A1-061-results.csv`
# prepare LandSurfaceTemperature
lst_day <- lst[c("Category", "Date", "MOD11A1_061_LST_Day_1km", "MOD11A1_061_QC_Day_MODLAND")]
lst_night <- lst[c("Category", "Date", "MOD11A1_061_LST_Night_1km", "MOD11A1_061_QC_Night_MODLAND")]
ndsi <- ndsi[c("Category", "Date", "MOD10A1_061_NDSI_Snow_Cover", "MOD10A1_061_NDSI_Snow_Cover_Basic_QA_Quality_Mask_Description")]
names(ndsi) <- c("Logger_ID", "Date", "SnowCover", "Quality")
# filter out all values that are not snow related
ndsi$SnowCover[ndsi$SnowCover >= 100 ] <- NA
# filter datasets
lst_day <- dplyr::filter(lst_day, MOD11A1_061_QC_Day_MODLAND %in% c("0b00", "0b01"))
names(lst_day) <- c("Logger_ID", "Date", "Temperature_Day", "Quality")
lst_night <- dplyr::filter(lst_night, MOD11A1_061_QC_Night_MODLAND %in% c("0b00", "0b01"))
names(lst_night) <- c("Logger_ID", "Date", "Temperature_Night", "Quality")
ndsi_daily <- filter_quality(ndsi, quality_column = Quality, c("Best", "Good", "OK"))
ndsi_daily <- mutate_dates(ndsi_daily, time_column = "Date", time_format = "%Y-%m-%d")
#combine datasets and convert in daily Temperature in degree Celisius
lst_combined <- left_join(lst_day, lst_night, by = c("Logger_ID", "Date"), suffix = c("_day", "_night"))
lst_daily <- lst_combined %>% mutate(Temperature_C = ((Temperature_Day + Temperature_Night) / 2) - 273.15)
usethis::use_data(lst_daily, overwrite = TRUE)
usethis::use_data(ndsi_daily, overwrite = TRUE)
usethis::use_r("lst_daily")
usethis::use_data(lst_daily, overwrite = TRUE)
devtools::check()
devtools::check()
usethis::use_r("ndsi_daily")
devtools::check()
lst_data <- lst_daily
ndsi_data <- ndsi_daily
View(ndsi_data)
library(fastR)
library(dplyr)
# function to filter quality
filter_quality <- function(data, quality_column, acceptable_qualities) {
data %>%
dplyr::filter({{ quality_column }} %in% acceptable_qualities)
}
create_subset <- function(data, columns) {
data %>%
dplyr::select({{ columns }})
}
merge_dataframes <- function(df1, df2) {
merged_df <- merge(df1, df2, by = "Date")
return(merged_df)
}
reference_data <- read_data("data-raw/raw-data/",add_ID_from_filename = FALSE )
lst <- reference_data$`example-lst-MOD11A1-061-results.csv`
ndsi <- reference_data$`example-ndsi-MOD10A1-061-results.csv`
# prepare LandSurfaceTemperature
lst_day <- lst[c("Category", "Date", "MOD11A1_061_LST_Day_1km", "MOD11A1_061_QC_Day_MODLAND")]
lst_night <- lst[c("Category", "Date", "MOD11A1_061_LST_Night_1km", "MOD11A1_061_QC_Night_MODLAND")]
ndsi <- ndsi[c("Category", "Date", "MOD10A1_061_NDSI_Snow_Cover", "MOD10A1_061_NDSI_Snow_Cover_Basic_QA_Quality_Mask_Description")]
names(ndsi) <- c("Logger_ID", "Date", "SnowCover", "Quality")
# filter out all values that are not snow related
ndsi$SnowCover[ndsi$SnowCover >= 100 ] <- NA
# filter datasets
lst_day <- dplyr::filter(lst_day, MOD11A1_061_QC_Day_MODLAND %in% c("0b00", "0b01"))
names(lst_day) <- c("Logger_ID", "Date", "Temperature_Day", "Quality")
lst_night <- dplyr::filter(lst_night, MOD11A1_061_QC_Night_MODLAND %in% c("0b00", "0b01"))
names(lst_night) <- c("Logger_ID", "Date", "Temperature_Night", "Quality")
ndsi_daily <- filter_quality(ndsi, quality_column = Quality, c("Best", "Good", "OK"))
ndsi_daily <- mutate_dates(ndsi_daily, time_column = "Date", time_format = "%Y-%m-%d")
#combine datasets and convert in daily Temperature in degree Celisius
lst_combined <- left_join(lst_day, lst_night, by = c("Logger_ID", "Date"), suffix = c("_day", "_night"))
lst_daily <- lst_combined %>% mutate(Temperature_C = ((Temperature_Day + Temperature_Night) / 2) - 273.15)
combined_data <- merge_dataframes(ndsi_daily, lst_daily)
View(combined_data)
str(combined_data)
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- lst_combined[, c("Date", "Julian", "Month", "Year", "Logger_ID", "Temperature_C", "SnowCover")]
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- lst_combined[, c("Date", "Julian", "Month", "Year", "Logger_ID.x", "Temperature_C", "SnowCover")]
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- lst_combined[, c("Date", "Julian", "Month", "Year", "Logger_ID.x", "Temperature_C", "SnowCover")]
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- lst_combined[, c("Date", "Julian", "Month", "Year", "Logger_ID.y", "Temperature_C", "SnowCover")]
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- lst_combined[, c("Date", "Logger_ID.x","Julian", "Month", "Year", "Temperature_C", "SnowCover")]
View(combined_data)
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- create_subset <- function(combined_data, columns= c("Date", "Logger_ID.x", "SnowCover", "Julian", "Month", "Year", "Temperature_C")) {
data %>%
dplyr::select({{ columns }})
}
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- create_subset <- function(combined_data, columns= c("Date", "Logger_ID.x", "SnowCover", "Julian", "Month", "Year", "Temperature_C"))
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- create_subset(combined_data, columns= c("Date", "Logger_ID.x", "SnowCover", "Julian", "Month", "Year", "Temperature_C"))
combined_data <- merge_dataframes(ndsi_daily, lst_daily)
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- create_subset(combined_data, columns= c("Date", "Logger_ID.x", "SnowCover", "Julian", "Month", "Year", "Temperature_C"))
# Subset the dataset to keep only the desired variables
lst_ndsi_subset <- # Subset the dataset to keep only the desired variables
lst_ndsi_subset <- combined_data[, c("Date", "Logger_ID.x", "SnowCover", "Julian", "Month", "Year", "Temperature_C")]
lst_ndsi_subset <- combined_data %>%
select(Date, Logger_ID.x, SnowCover, Julian, Month, Year, Temperature_C) %>%
rename(Logger_ID = Logger_ID.x)
View(lst_ndsi_subset)
lst_ndsi_subset <- combined_data %>%
select(Date, Logger_ID.x, SnowCover, Julian, Month, Year, Temperature_C) %>%
rename(Logger_ID = Logger_ID.x,
LST_C = Temperature_C)
usethis::use_data(lst_ndsi_subset, overwrite = TRUE)
usethis::use_r("lst_ndsi_subset")
devtools::check()
devtools::check()
devtools::check()
library(fastR)
devtools::build_readme()
