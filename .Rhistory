mutate_operations <- list(
Time = as.POSIXct(Time, format = "%d.%m.%Y %H:%M:%S"),
Date = as.Date(Time),
Julian = lubridate::yday(Time),
Month = factor(month.name[as.integer(format(Time, "%m"))], levels = month.name),
Year = lubridate::year(Time)
)
mutate_operations <- list(
Time = as.POSIXct(ds$Time, format = "%d.%m.%Y %H:%M:%S"),
Date = as.Date(ds$Time),
Julian = lubridate::yday(ds$Time),
Month = factor(month.name[as.integer(format(ds$Time, "%m"))], levels = month.name),
Year = lubridate::year(ds$Time)
)
mutate_operations <- list(
Time = ~ as.POSIXct(Time, format = "%d.%m.%Y %H:%M:%S")
)
for (i in mutate_operations){}
for (i in mutate_operations){ mutated_df <- dplyr::mutate(df, operation)}
for (i in mutate_operations){ mutated_df <- dplyr::mutate(df, !!operation)}
for (i in mutate_operations){ mutated_df <- dplyr::mutate_all(df, !!operation)}
for (i in mutate_operations){ mutated_df <- dplyr::mutate_all(df, operation)}
View(mutated_df)
mutate_operations <- list(
Time = ~ as.POSIXct(Time, format = "%d.%m.%Y %H:%M:%S"),
Date = ~ as.Date(Time),
Julian = ~ lubridate::yday(Time),
Month = ~ factor(month.name[as.integer(format(Time, "%m"))], levels = month.name),
Year = ~ lubridate::year(Time)
)
for (i in mutate_operations){ mutated_df <- dplyr::mutate_all(df, operation)}
View(mutated_df)
for (i in mutate_operations){ mutated_df <- dplyr::mutate_all(df, i)}
args <- mutate_operations
args
rlang::enexpr(args)
print(rlang::enexpr(args))
print(rlang::enexpr(args))
print(str(rlang::enexpr(args)))
print(str(rlang::lang_args(args)))
test <- function(df, args){
args_call <- rlang::enexpr(args)
list_of_arg <- rlang::call_args_names(args_call)
print(list_of_arg))
test <- function(df, args){
args_call <- rlang::enexpr(args)
list_of_arg <- rlang::call_args_names(args_call)
print(list_of_arg)
}
t <- test(df, args = args)
rlang::last_trace()
devtools::document
devtools::document()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::build()
library(loggeranalysis)
library(loggeranalysis)
devtools::check()
devtools::check()
library(loggeranalysis)
devtools::check()
library(loggeranalysis)
library(loggeranalysis)
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
library(loggeranalysis)
45-18
library(loggeranalysis)
library(loggeranalysis)
library(loggeranalysis)
devtools::check()
library(loggeranalysis)
library(loggeranalysis)
library(loggeranalysis)
library(loggeranalysis)
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
usethis::use_package("sf")
devtools::check()
library(loggeranalysis)
devtools::check()
getwd
getwd()
source("~/R/create_setup_file.R")
source("/home/ela/Documents/R-Projects/loggeranalysis/R/create_setup_file.R")
appeears_login <- function(){
source("/home/ela/Documents/R-Projects/loggeranalysis/R/create_setup_file.R")
api_url <- 'https://appeears.earthdatacloud.nasa.gov/api/'
secret <- jsonlite::base64_enc(gsub(' ', '', paste(gsub('login ', '', readLines(file.path(Sys.getenv('HOME'), ".netrc", fsep = .Platform$file.sep))[2])
, gsub('password ', '', readLines(file.path(Sys.getenv('HOME'), ".netrc", fsep = .Platform$file.sep))[3])
, sep = ":")))
print(secret)
}
test <- appears_login()
appeears_login <- function(){
source("/home/ela/Documents/R-Projects/loggeranalysis/R/create_setup_file.R")
api_url <- 'https://appeears.earthdatacloud.nasa.gov/api/'
secret <- jsonlite::base64_enc(gsub(' ', '', paste(gsub('login ', '', readLines(file.path(Sys.getenv('HOME'), ".netrc", fsep = .Platform$file.sep))[2])
, gsub('password ', '', readLines(file.path(Sys.getenv('HOME'), ".netrc", fsep = .Platform$file.sep))[3])
, sep = ":")))
print(secret)
}
test <- appeears_login()
appeears_login <- function(){
netrc_path <- source("/home/ela/Documents/R-Projects/loggeranalysis/R/create_setup_file.R")
netrc_lines <- readLines(netrc_path)
api_url <- 'https://appeears.earthdatacloud.nasa.gov/api/'
#login <- gsub('login', "", )
# readLines reads .netrc file
# gsub removes any spaces inside the file
# paste stores the login and password with a : inbetween
# secret <- jsonlite::base64_enc(gsub(' ', '', paste(gsub('login ', '', readLines(file.path(Sys.getenv('HOME'), ".netrc", fsep = .Platform$file.sep))[2])
, gsub('password ', '', readLines(file.path(Sys.getenv('HOME'), ".netrc", fsep = .Platform$file.sep))[3])
test <- appeears_login()
appeears_login <- function(){
netrc_path <- source("/home/ela/Documents/R-Projects/loggeranalysis/R/create_setup_file.R")
netrc_lines <- readLines(netrc_path)
api_url <- 'https://appeears.earthdatacloud.nasa.gov/api/'
#login <- gsub('login', "", )
# readLines reads .netrc file
# gsub removes any spaces inside the file
# paste stores the login and password with a : inbetween
# # secret <- jsonlite::base64_enc(gsub(' ', '', paste(gsub('login ', '', readLines(file.path(Sys.getenv('HOME'), ".netrc", fsep = .Platform$file.sep))[2])
#                                                     , gsub('password ', '', readLines(file.path(Sys.getenv('HOME'), ".netrc", fsep = .Platform$file.sep))[3])
#                                                     , sep = ":")))
#
print(netrc_lines)
}
test <- appeears_login()
devtools::check()
usethis::use_package("httr")
usethis::use_package("jsonlite")
devtools::check()
devtools::check()
devtools::check()
devtools::check()
library(loggeranalysis)
usethis::use_package("httr")
usethis::use_package("jsonlite")
devtools::check()
devtools::check()
devtools::check()
devtools::check()
library(loggeranalysis)
devtools::check()
devtools::check()
library(loggeranalysis)
devtools::check()
library(loggeranalysis)
library(loggeranalysis)
library(loggeranalysis)
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::load_all()
devtools::check()
devtools::load_all()
devtools::check()
devtools::check()
devtools::check()
usethis::use_package("httr")
usethis::use_package("ggplot2")
devtools::load_all()
devtools::check()
library(fastR)
library(fastR)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
library(fastR)
devtools::document()
library(fastR)
devtools::document()
devtools::check()
devtools::document()
devtools::check()
library(fastR)
devtools::check()
library(fastR)
library(fastR)
library(fastR)
library(fastR)
devtools::check()
create_yearly_overview_plot <- function(daily_data, title){
# Check if daily_data is a list of data frames or a single data frame
if (!is.data.frame(daily_data)) {
# If daily_data is a list, combine data frames into a single data frame
daily_temperature <- dplyr::bind_rows(daily_data)
} else {
# If daily_data is already a single data frame, use it directly
daily_temperature <- daily_data
}
yearly_overview <- ggplot2::ggplot(daily_temperature, aes(x = Date, y = mean_temperature))+
ggplot2::geom_line(color = '#6bd2db', linewidth = 1)+
ggplot2::geom_smooth()+
# theme(panel.grid = element_line(color = "#8ccde3", size = 0.5, linetype = 2))+
ggplot2::theme(panel.grid.major = ggplot2::element_line(color = "#0c457d",
linewidth = 0.5,
linetype = 2))+
ggplot2::theme(panel.grid.minor.x = element_line(color = "#6d8fb1",
linewidth = 0.25,
linetype = 1))+
ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
axis.title.x = element_blank(),
axis.title.y = element_blank())+
ggplot2::labs(x = "Year",
y = "Mean Temperature")+
ggplot2::facet_wrap(~Logger_ID)+
ggplot2::ggtitle(title)
return(yearly_overview)
}
devtools::check()
library(fastR)
library(fastR)
library(fastR)
library(dplyr)
library(ggplot2)
create_subset <- function(data, columns, start_date, end_date) {
data %>%
filter(Date >= start_date & Date <= end_date) %>%
select(columns)
}
merge_dataframes <- function(df1, df2) {
merged_df <- merge(df1, df2, by = "Date")
return(merged_df)
}
ndsi <- read_data("/home/ela/Documents/R-FinalExam/ndsi_data/", add_ID_from_filename = FALSE)
lst <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
ndsi_data <- list()
for (i in seq_along(ndsi)) {
ndsi_data[[i]] <- ndsi[[i]][,c("Logger_ID", "Date", "SnowCover", "Quality")]
}
for (i in seq_along(ndsi_data)){
df_Time_mutated <- mutate_dates(df = ndsi_data[[i]], time_column = "Date", time_format = "%Y-%m-%d")
ndsi_data[[i]] <- df_Time_mutated
names(ndsi_data)[i] <- unique(df_Time_mutated$Logger_ID)
}
remove(df_Time_mutated)
#read in logger data
input_directory <- "/home/ela/Documents/R-FinalExam/Muragl/"
list_of_raw_data <- read_data(input_directory = input_directory)
datasets <- list()
for (i in seq_along(list_of_raw_data)){
df_renamed_columns <- rename_columns(list_of_raw_data[[i]])
datasets[[i]] <- df_renamed_columns
names(datasets)[i] <- unique(df_renamed_columns$Logger_ID)
}
remove(df_renamed_columns)
# mutate the Time column, so the dataaggregation can be done
for (i in seq_along(datasets)){
df_Time_mutated <- mutate_dates(df = datasets[[i]], time_column = "Time", time_format = "%d.%m.%Y %H:%M:%S")
datasets[[i]] <- df_Time_mutated
names(datasets)[i] <- unique(df_Time_mutated$Logger_ID)
}
remove(df_Time_mutated)
for (i in seq_along(datasets)) {
datasets[[i]] <- create_subset(datasets[[i]], c("Number", "Time", "Temperature_C", "Logger_ID", "Date", "Julian", "Month", "Year"),
start_date = as.Date("2011-01-01"),
end_date = as.Date("2022-12-29"))
#names(datasets)[i] <- unique(df_Time_mutated$Logger_ID)
}
daily_data <- list()
for (i in seq_along(datasets)){
df_daily <- aggregate_data(df = datasets[[i]], aggregation_type = "daily", temperature_column = "Temperature_C")
daily_data[[i]] <- df_daily
names(daily_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_daily)
# Loop through the common dates and merge corresponding data frames
merged_datasets <- list()
common_dates <- intersect(names(ndsi_data), names(daily_data))
for (date in common_dates) {
merged_datasets[[date]] <- merge_dataframes(daily_data[[date]], ndsi_data[[date]])
merged_datasets[[date]] <- merged_datasets[[date]][, c("Date", "mean_temperature", "std_temperature",
"min_temperature", "max_temperature", "Logger_ID.x",
"Month.x", "Year.x", "Julian.x", "SnowCover", "Quality")]
}
plots <- list()
for (logger_id in names(merged_datasets)){
plot <- ggplot(merged_datasets[[logger_id]], aes(x = Julian.x, y=mean_temperature))+
geom_line(aes(y = mean_temperature), show.legend = TRUE)+
geom_point(aes(y = SnowCover))+
scale_y_continuous(
name = "Mean Temperature",
sec.axis = sec_axis(trans = ~.*0.3, name = "Snow Coverage"))+
facet_wrap(~Year.x)
plots[[logger_id]] <- plot
}
plots$A50276
library(fastR)
############### LOGGER
#read in logger data
input_directory <- "/home/ela/Documents/R-FinalExam/Muragl/"
list_of_raw_data <- read_data(input_directory = input_directory)
datasets <- list()
for (i in seq_along(list_of_raw_data)){
df_renamed_columns <- rename_columns(list_of_raw_data[[i]])
datasets[[i]] <- df_renamed_columns
names(datasets)[i] <- unique(df_renamed_columns$Logger_ID)
}
remove(df_renamed_columns)
# mutate the Time column, so the dataaggregation can be done
for (i in seq_along(datasets)){
df_Time_mutated <- mutate_dates(df = datasets[[i]], time_column = "Time", time_format = "%d.%m.%Y %H:%M:%S")
datasets[[i]] <- df_Time_mutated
names(datasets)[i] <- unique(df_Time_mutated$Logger_ID)
}
remove(df_Time_mutated)
lst_data <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
annual_data <- list()
monthly_data <- list()
daily_data <- list()
seasonal_data <- list()
#annual
for (i in seq_along(datasets)){
df_annual <- aggregate_data(df = datasets[[i]], aggregation_type = "annual", temperature_column = "Temperature_C")
annual_data[[i]] <- df_annual
names(annual_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_annual)
#monthly
for (i in seq_along(datasets)){
df_monthly <- aggregate_data(df = datasets[[i]], aggregation_type = "monthly", temperature_column = "Temperature_C")
monthly_data[[i]] <- df_monthly
names(monthly_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_monthly)
# daily
for (i in seq_along(datasets)){
df_daily <- aggregate_data(df = datasets[[i]], aggregation_type = "daily", temperature_column = "Temperature_C")
daily_data[[i]] <- df_daily
names(daily_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_daily)
# seasonal
for (i in seq_along(datasets)){
df_season <- aggregate_data(df = datasets[[i]], aggregation_type = "seasonal", temperature_column = "Temperature_C")
seasonal_data[[i]] <- df_season
names(seasonal_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_season)
# plot daily data for each site and the whole time period
library(dplyr)
library(ggplot2)
daily_temperature <- bind_rows(daily_data)
library(dplyr)
library(ggplot2)
##################################PLOTTING WITH FUNCTIONS
# plot
yearly_plot <- create_yearly_overview_plot(daily_data, title = "Muragl - Overview over Temperature Developement for each Site" )
yearly_plot
# yearly_plot_ndsi <- create_yearly_overview_plot(daily_ndsi, title = "Overview over Snow Cover Developement for each Site")
#creaty daily plot, grouped by site
daily_plots <- create_daily_plots(daily_data)
daily_plots$A50276
# Create monthly plots by site
monthly_plots_by_site <- create_monthly_plots_by_site(monthly_data)
monthly_lst_plots_by_site <- create_monthly_plots_by_site(monthly_lst)
# Create monthly plots by month
monthly_plots_by_month <- create_monthly_plots_by_month(monthly_data)
monthly_plots_by_site$A50276
monthly_plots_by_month$January
lst <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
lst <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
lst_data <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
# create subsets
for (i in seq_along(lst_data)){
lst_data[[i]] <- lst_data[[i]][,c("Logger_ID", "Date", "Temperature_C")]
}
for (i in seq_along(lst_data)){
df_Time_mutated <- mutate_dates(df = lst_data[[i]], time_column = "Date", time_format = "%Y-%m-%d")
lst_data[[i]] <- df_Time_mutated
names(lst_data)[i] <- unique(df_Time_mutated$Logger_ID)
}
#monthly
for (i in seq_along(lst_data)){
df_monthly <- aggregate_data(df = lst_data[[i]], aggregation_type = "monthly", temperature_column = "Temperature_C")
monthly_lst[[i]] <- df_monthly
names(monthly_lst)[i] <- unique(lst_data[[i]]$Logger_ID)
}
usethis::use_data()
system.file("extdata", package = "readxl")|> list.files()
A50276_20231006143640 <- read.csv("~/Documents/R-FinalExam/Muragl/A50276_20231006143640.csv", comment.char="#")
View(A50276_20231006143640)
usethis::use_data(A50276_20231006143640)
usethis::use_r("data")
load("/home/ela/Downloads/aoi_data.rda")
aoi_data
remove(aoi_data)
library(loggeranalysis)
input_directory <- system.file("extdata", package = "fastR")
## basic example code
library(fastR)
input_directory <- system.file("extdata", package = "fastR")
## basic example code
input_directory
devtools::load_all()
devtools::check()
devtools::check()
library(fastR)
library(fastR)
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger_ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
# take a look at the structure of raw_data and one dataset
str(raw_data)
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger.ID = "Logger_ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M:%S")
head(sample_data)
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M:%S")
head(sample_data)
