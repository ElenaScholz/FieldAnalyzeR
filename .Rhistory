for (date in common_dates) {
merged_datasets[[date]] <- merge_dataframes(daily_data[[date]], ndsi_data[[date]])
merged_datasets[[date]] <- merged_datasets[[date]][, c("Date", "mean_temperature", "std_temperature",
"min_temperature", "max_temperature", "Logger_ID.x",
"Month.x", "Year.x", "Julian.x", "SnowCover", "Quality")]
}
plots <- list()
for (logger_id in names(merged_datasets)){
plot <- ggplot(merged_datasets[[logger_id]], aes(x = Julian.x, y=mean_temperature))+
geom_line(aes(y = mean_temperature), show.legend = TRUE)+
geom_point(aes(y = SnowCover))+
scale_y_continuous(
name = "Mean Temperature",
sec.axis = sec_axis(trans = ~.*0.3, name = "Snow Coverage"))+
facet_wrap(~Year.x)
plots[[logger_id]] <- plot
}
plots$A50276
library(fastR)
############### LOGGER
#read in logger data
input_directory <- "/home/ela/Documents/R-FinalExam/Muragl/"
list_of_raw_data <- read_data(input_directory = input_directory)
datasets <- list()
for (i in seq_along(list_of_raw_data)){
df_renamed_columns <- rename_columns(list_of_raw_data[[i]])
datasets[[i]] <- df_renamed_columns
names(datasets)[i] <- unique(df_renamed_columns$Logger_ID)
}
remove(df_renamed_columns)
# mutate the Time column, so the dataaggregation can be done
for (i in seq_along(datasets)){
df_Time_mutated <- mutate_dates(df = datasets[[i]], time_column = "Time", time_format = "%d.%m.%Y %H:%M:%S")
datasets[[i]] <- df_Time_mutated
names(datasets)[i] <- unique(df_Time_mutated$Logger_ID)
}
remove(df_Time_mutated)
lst_data <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
annual_data <- list()
monthly_data <- list()
daily_data <- list()
seasonal_data <- list()
#annual
for (i in seq_along(datasets)){
df_annual <- aggregate_data(df = datasets[[i]], aggregation_type = "annual", temperature_column = "Temperature_C")
annual_data[[i]] <- df_annual
names(annual_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_annual)
#monthly
for (i in seq_along(datasets)){
df_monthly <- aggregate_data(df = datasets[[i]], aggregation_type = "monthly", temperature_column = "Temperature_C")
monthly_data[[i]] <- df_monthly
names(monthly_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_monthly)
# daily
for (i in seq_along(datasets)){
df_daily <- aggregate_data(df = datasets[[i]], aggregation_type = "daily", temperature_column = "Temperature_C")
daily_data[[i]] <- df_daily
names(daily_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_daily)
# seasonal
for (i in seq_along(datasets)){
df_season <- aggregate_data(df = datasets[[i]], aggregation_type = "seasonal", temperature_column = "Temperature_C")
seasonal_data[[i]] <- df_season
names(seasonal_data)[i] <- unique(datasets[[i]]$Logger_ID)
}
remove(df_season)
# plot daily data for each site and the whole time period
library(dplyr)
library(ggplot2)
daily_temperature <- bind_rows(daily_data)
library(dplyr)
library(ggplot2)
##################################PLOTTING WITH FUNCTIONS
# plot
yearly_plot <- create_yearly_overview_plot(daily_data, title = "Muragl - Overview over Temperature Developement for each Site" )
yearly_plot
# yearly_plot_ndsi <- create_yearly_overview_plot(daily_ndsi, title = "Overview over Snow Cover Developement for each Site")
#creaty daily plot, grouped by site
daily_plots <- create_daily_plots(daily_data)
daily_plots$A50276
# Create monthly plots by site
monthly_plots_by_site <- create_monthly_plots_by_site(monthly_data)
monthly_lst_plots_by_site <- create_monthly_plots_by_site(monthly_lst)
# Create monthly plots by month
monthly_plots_by_month <- create_monthly_plots_by_month(monthly_data)
monthly_plots_by_site$A50276
monthly_plots_by_month$January
lst <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
lst <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
lst_data <- read_data("/home/ela/Documents/R-FinalExam/lst_data/", add_ID_from_filename = FALSE)
# create subsets
for (i in seq_along(lst_data)){
lst_data[[i]] <- lst_data[[i]][,c("Logger_ID", "Date", "Temperature_C")]
}
for (i in seq_along(lst_data)){
df_Time_mutated <- mutate_dates(df = lst_data[[i]], time_column = "Date", time_format = "%Y-%m-%d")
lst_data[[i]] <- df_Time_mutated
names(lst_data)[i] <- unique(df_Time_mutated$Logger_ID)
}
#monthly
for (i in seq_along(lst_data)){
df_monthly <- aggregate_data(df = lst_data[[i]], aggregation_type = "monthly", temperature_column = "Temperature_C")
monthly_lst[[i]] <- df_monthly
names(monthly_lst)[i] <- unique(lst_data[[i]]$Logger_ID)
}
usethis::use_data()
system.file("extdata", package = "readxl")|> list.files()
A50276_20231006143640 <- read.csv("~/Documents/R-FinalExam/Muragl/A50276_20231006143640.csv", comment.char="#")
View(A50276_20231006143640)
usethis::use_data(A50276_20231006143640)
usethis::use_r("data")
load("/home/ela/Downloads/aoi_data.rda")
aoi_data
remove(aoi_data)
library(loggeranalysis)
input_directory <- system.file("extdata", package = "fastR")
## basic example code
library(fastR)
input_directory <- system.file("extdata", package = "fastR")
## basic example code
input_directory
devtools::load_all()
devtools::check()
devtools::check()
library(fastR)
library(fastR)
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger_ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
# take a look at the structure of raw_data and one dataset
str(raw_data)
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger.ID = "Logger_ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M:%S")
head(sample_data)
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M:%S")
head(sample_data)
library(fastR)
library(fastR)
input_directory <- system.file("extdata/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
input_directory <- system.file("extdata/Logger/", package = "fastR")
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
library(fastR)
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
library(fastR)
library(fastR)
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M:%S")
head(sample_data)
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M:%S")
head(sample_data)
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Logger/", package = "fastR"), add_ID_from_filename = FALSE)
str(coordinates)
head(coordiantes)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Logger/", package = "fastR"), add_ID_from_filename = FALSE)
str(coordinates)
head(coordinates)
View(coordinates)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
str(coordinates)
head(coordinates)
devtools::load_all()
devtools::check()
library(fastR)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
str(coordinates)
head(coordinates)
# for the further analysis the columns
library(fastR)
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
str(coordinates)
head(coordinates)
# for the further analysis the columns
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84")
View(coordinates_transformed)
coordinates_df <- coordinates_transformed %>%
sf::st_coordinates() %>%
as.data.frame() %>%
mutate(longitude = X,
latitude = Y) %>%
tibble::rowid_to_column("id") %>%
select(id, longitude, latitude) %>%
bind_cols(category = coordinates_transformed$Logger_ID)
coordinates_df <- coordinates_transformed %>%
sf::st_coordinates() %>%
as.data.frame() %>%
mutate(longitude = X,
latitude = Y) %>%
tibble::rowid_to_column("id") %>%
select(id, longitude, latitude) %>%
dplyr::bind_cols(category = coordinates_transformed$Logger_ID)
coordinates_df <- coordinates_transformed %>%
sf::st_coordinates() %>%
as.data.frame() %>%
mutate(longitude = X,
latitude = Y) %>%
tibble::rowid_to_column("id") %>%
dplyr::select(id, longitude, latitude) %>%
dplyr::bind_cols(category = coordinates_transformed$Logger_ID)
coordinates_df <- coordinates_transformed %>%
sf::st_coordinates() %>%
as.data.frame() %>%
dplyr::mutate(longitude = X,
latitude = Y) %>%
tibble::rowid_to_column("id") %>%
dplyr::select(id, longitude, latitude) %>%
dplyr::bind_cols(category = coordinates_transformed$Logger_ID)
View(coordinates_df)
devtools::load_all()
devtools::check
devtools::check()
devtools::load_all()
devtools::check()
usethis::use_package("tibble")
devtools::check()
library(fastR)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is an sf-object
class(coordinates_transformed)
coordinates_transformed$coordinates_df
appeears_coordinates <- coordinates_transformed$coordinates_df
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
### 5. submit a processing task for the reference data
# in this case reference data for landsurface temperature (LST) and        Snow Cover is chosen (NDSI)
start_date <- min(sample_data$Date)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, filter_topic = "LST", token = token, start_date = start_date, end_date = end_date)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
### 2. create a spatial dataset, that converts the original                   coordinatesystem into longitude and latitude
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is a list containing an sf-object and a dataframe      for the download
class(coordinates_transformed)
appeears_coordinates <- coordinates_transformed$coordinates_df
### 3. Login to AppEEARS and generate a token
token <- appeears_login()
### 4. get an overview over all appeears products and choose which reference data you want to download
products <- show_appeears_products()
### 5. submit a processing task for the reference data
# in this case reference data for landsurface temperature (LST) and        Snow Cover is chosen (NDSI)
start_date <- min(sample_data$Date)
end_date <- max(sample_data$Date)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date)
devtools::load_all()
devtools::check()
library(fastR)
library(fastR)
input_directory <- system.file("extdata/Logger/", package = "fastR")
### 1. Read in the Datasets with the function "read_data"
# for the given example datasets, the ID can be added from the filename.
raw_data <- read_data(input_directory = input_directory, csv_sep = ",",
csv_comment_character = "#",
add_ID_from_filename = TRUE,
index_id = c(0, 6)
)
# take a look at the structure of raw_data and one dataset
str(raw_data)
### 2. Rename the columns to make the Analysis easier
sample_data <- rename_columns(raw_data,
rename_map = list(Number = "No",
Logger_ID = "Logger.ID",
Time = "Time",
Temperature_C  = "X1.oC",
Battery_Voltage = "HK.Bat.V"))
### 3. Date Conversion
# for further analysis it is necessary to have the Date converted to the type         "Date". Therefore check if the format of the Time Column.
sample_data <- mutate_dates(sample_data, time_column = "Time",
time_format = "%d.%m.%Y %H:%M")
head(sample_data)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
### 2. create a spatial dataset, that converts the original                   coordinatesystem into longitude and latitude
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is a list containing an sf-object and a dataframe      for the download
class(coordinates_transformed)
appeears_coordinates <- coordinates_transformed$coordinates_df
### 3. Login to AppEEARS and generate a token
token <- appeears_login()
### 4. get an overview over all appeears products and choose which reference data you want to download
products <- show_appeears_products()
### 5. submit a processing task for the reference data
# in this case reference data for landsurface temperature (LST) and        Snow Cover is chosen (NDSI)
start_date <- min(sample_data$Date)
end_date <- max(sample_data$Date)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date)
View(appeears_coordinates)
class(appeears_coordinates)
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date, coordinates_dataframe = appeears_coordinates)
### 1. Load in Coordinate file and examine the structure
coordinates <- read_data(input_directory = system.file("extdata/Coordinates/", package = "fastR"), add_ID_from_filename = FALSE)
# Look at the dataset - it contains information about x and y            position
str(coordinates)
head(coordinates)
### 2. create a spatial dataset, that converts the original                   coordinatesystem into longitude and latitude
coordinates_transformed <- make_spatial_data(coordinates, coordinate_column = c("X", "Y"), data_crs_original = coordinates$EPSG, transformed_crs = "+proj=longlat +datum=WGS84", logger_id_column = "Logger.ID")
# the new dataset is a list containing an sf-object and a dataframe      for the download
class(coordinates_transformed)
appeears_coordinates <- coordinates_transformed$coordinates_df
### 3. Login to AppEEARS and generate a token
token <- appeears_login()
### 4. get an overview over all appeears products and choose which reference data you want to download
products <- show_appeears_products()
### 5. submit a processing task for the reference data
# in this case reference data for landsurface temperature (LST) and        Snow Cover is chosen (NDSI)
# make sure the format of the dates is in m-d-Y
start_date <- "01-01-2010"
end_date <- "06-10-2023"
lst_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "LST", token = token, start_date = start_date, end_date = end_date, coordinates_dataframe = appeears_coordinates)
ndsi_submission <- submit_processing_task(task_name = "example_lst", products_df = products, topic_filter = "NDSI", token = token, start_date = start_date, end_date = end_date, coordinates_dataframe = appeears_coordinates)
### 6. download the reference data
getwd()
devtools::build_readme()
devtools::build_readme()
.Last.error
devtools::build_readme()
devtools::build_readme()
devtools::check()
library(fastR)
devtools::build_readme()
devtools::build_readme()
